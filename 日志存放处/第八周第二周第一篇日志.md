# 第八周第二周第一篇日志

## 学习目标

学习神经网络

## 成果展示

import numpy as np
from keras.models import Sequential　　# Kera的基础模型类
from keras.layers import Dense, Activation　　# Dense是神经元的全连接层
from keras.optimizers import SGD　　# 随机梯度下降，Keras中还有一些其他优化器

\# Our examples for an exclusive OR.

x_train = np.array([[0, 0],
                    [0, 1],
                    [1, 0],
                    [1, 1]]) 　　# x_train是二维特征向量表示的训练样本列表
y_train = np.array([[0],
                    [1],
                    [1],
                    [0]]) 　　# y_train是每个特征向量样本对应的目标输出值
model = Sequential()
num_neurons = 10　　#　全连接隐藏层包含10个神经元
model.add(Dense(num_neurons, input_dim=2)) 　　#　 input_dim仅在第一层中使用，后面的其他层会自动计算前一层输出的形状，这个例子中输入的XOR样本是二维特征向量，因此input_dim设置为2
model.add(Activation('tanh'))
model.add(Dense(1)) 　　#　输出层包含一个神经元，输出结果是二分类值（0或1）
model.add(Activation('sigmoid'))
model.summary()

从网上看到一篇用原生Python来编写神经网络的文章，然后学习了他，用Keras来训练这个网络

## 学习中的问题

机器学习还没有学好，然后直接学习神经网络了，有些好高骛远了，学的不扎实，有很多都是一知半解，下一阶段要先把机器学习学好