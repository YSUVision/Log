# 一 学习内容（对预测代码部分的初步学习）

一、数据变量的定义

1对数据点 (x,y)，通过函数 (f(x) = ax^2 + bx + c)，使得这个函数与数据点的残差平方和最小化。

残差是每个数据点 ( (x,y) ) 的观测值 ( y_i ) 与二次函数 ( at_i^2 + bt_i + c ) 的预测值之间的差异。

​    所以问题的目标是找到系数 ( a ), ( b ), ( c )，使得所有数据点的残差平方和最小。用于拟合数据并找到最佳拟合曲线或曲面，以便描述数据的整体趋势。

2接着是对abc求偏导数，并令式子等于零 可以得到最优的二次拟合曲线，使得拟合误差的平方和最小化。然后便可化成矩阵的式子(T^T T + lambda R) *beta= T^T Y 带入数值即可解出abc的值

二、代码部分

构造设计矩阵 `T` 和响应向量 Y

gsl_matrix *T = gsl_matrix_alloc(n, p);

分配了一个n乘p的矩阵 T，用于存储设计矩阵。

gsl_vector *Y = gsl_vector_alloc(n);分配了一个长度为 `n` 的 向量 Y，用于存储响应变量。

for (int i = 0; i < n; i++) { ... }

循环遍历每个数据点。

double ti = d.t[i]/time_resize将时间值 d.t[i] 缩放为 ti，以匹配前面提到的时间缩放操作。

gsl_matrix_set(T, i, 0, ti * ti);设置设计矩阵 T的第 行、第 0 列为 ( ti^2 )。

gsl_matrix_set(T, i, 1, ti);设置设计矩阵 `T` 的第 `i` 行、第 1 列为 `ti`。`

gsl_matrix_set(T, i, 2, 1.0);设置设计矩阵 `T` 的第 `i` 行、第 2 列为常数项 `1.0`。`

gsl_vector_set(Y, i, d.y[i]);设置响应向量 `Y` 的第 `i` 个元素为对应的观测值 `d.y[i]`。

构造正则化矩阵 R

double lambda = 0.1定义了正则化参数 lambda

gsl_matrix *R = gsl_matrix_alloc(p, p)分配了一个 p x p 的 GSL 矩阵 R，用于存储正则化矩阵。

## 正则化矩阵过程

gsl_matrix_set_zero(R);`：将矩阵 `R` 的所有元素初始化为零

gsl_matrix_set(R, 0, 0, lambda);`：设置矩阵 `R` 的第 0 行、第 0 列为 `lambda

gsl_matrix_set(R, 1, 1, lambda);`：设置矩阵 `R` 的第 1 行、第 1 列为 `lambda

gsl_matrix_set(R, 2, 2, lambda);`：设置矩阵 `R` 的第 2 行、第 2 列为 `lambda

gsl_matrix \*TtT = gsl_matrix_alloc(p, p);

这行代码分配了一个大小为 ( p \times p ) 的矩阵 TtT，用于存储 ( T^T T + \lambda R ) 的结果。在这里，( p ) 是参数数量，通常是 3，对应于二次多项式的参数 ( a, b, c )。

gsl_blas_dgemm(CblasTrans, CblasNoTrans, 1.0, T, T, 0.0, TtT);

gsl_blas_dgemm是 GSL 库中进行矩阵乘法的函数。

CblasTrans表示进行矩阵乘法时将第一个矩阵 ( T ) 进行转置。

CblasNoTrans表示第二个矩阵 ( T ) 不进行转置。

1.0是乘法的比例因子，表示乘法结果的权重。

T, T是要相乘的两个矩阵，即 ( T^T \cdot T )。

0.0表示结果矩阵 TtT初始时要加的常数，这里是 0，因为我们希望直接用乘法结果填充 TtT

这行代码的效果是将 ( T^T \cdot T ) 的结果存储在 TtT中。

gsl_matrix_add(TtT, R);

这行代码将之前计算的 ( T^T \cdot T ) 结果矩阵 TtT和正则化矩阵 R相加。

对于每个对应的元素，它们分别相加，因为两个矩阵的尺寸都是 ( p \times p )。

## 解线性方程组

其中 ( X ) 是设计矩阵，( Y ) 是观测值向量，( \beta ) 是要求解的参数向量，( \lambda ) 是正则化参数，( R ) 是正则化矩阵。

让我们逐行解释代码：

gsl_vector \*beta = gsl_vector_alloc(p);

这行代码创建了一个大小为 ( p ) 的向量 beta，用于存储线性方程组的解，即模型参数 ( \beta )。

gsl_permutation \*perm = gsl_permutation_alloc(p);

gsl_permutation 是 GSL 中用于存储 LU 分解结果的数据结构

这行代码创建了一个大小为 ( p ) 的置换向量 perm，用于存储 LU 分解中的置换信息

int signum;

signum是一个整数，用于存储 LU 分解的符号

gsl_linalg_LU_decomp(TtT, perm, &signum);

gsl_linalg_LU_decomp是 GSL 提供的进行 LU 分解的函数

TtT是上一个步骤中计算的 ( T^T T + \lambda R ) 的结果矩阵

perm 是置换向量，用于存储 LU 分解中的置换信息

&signum是一个指向 signum的指针，用于存储 LU 分解的符号（正负号）

这行代码执行了 LU 分解，将 ( T^T T + \lambda R ) 分解为下三角矩阵 ( L ) 和上三角矩阵 ( U )，并且通过置换向量 perm记录置换的过程。

gsl_linalg_LU_solve(TtT, perm, TtY, beta);

gsl_linalg_LU_solve 是 GSL 中用于解已经进行了 LU 分解的线性方程组的函数。

TtT是 LU 分解后的矩阵 ( T^T T + \lambda R )。

perm 是 LU 分解中记录的置换信息。

TtY是右侧的向量 ( X^T Y )。

beta 是存储解 ( \beta ) 的向量。

这行代码将解 ( \beta ) 存储在 beta向量中

# 三 学习中遇到的问题

还需要进一步代码测试

旅行过程中时间较少，后续会加大对代码部分的熟悉

# 四 总结与反思

对于预测部分代码的矩阵部分还不熟悉，后续许反复复习